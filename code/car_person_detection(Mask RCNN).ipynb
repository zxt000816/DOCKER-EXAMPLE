{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zyf13\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15632\\3818868836.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[1;31m# opencv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 # opencv\n",
    "from urllib.request import urlopen\n",
    "import random\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # For high res images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "len(COCO_INSTANCE_CATEGORY_NAMES) # 91 classes including background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(img_path, threshold=0.5, url=False):\n",
    "  if url: \n",
    "    response = requests.get(img_path)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "  else:\n",
    "    img = Image.open(img_path) \n",
    "  transform = T.Compose([T.ToTensor()]) # Turn the image into a torch.tensor\n",
    "  img = transform(img)\n",
    "  img = img.cuda() \n",
    "  pred = model([img]) \n",
    "  pred_score = list(pred[0]['scores'].detach().cpu().numpy())\n",
    "  pred_t = [pred_score.index(x) for x in pred_score if x > threshold][-1]\n",
    "  masks = (pred[0]['masks'] > 0.5).squeeze().detach().cpu().numpy()\n",
    "  pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].cpu().numpy())]\n",
    "  pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().cpu().numpy())]\n",
    "  masks = masks[:pred_t+1]\n",
    "  pred_boxes = pred_boxes[:pred_t+1]\n",
    "  pred_class = pred_class[:pred_t+1]\n",
    "  return masks, pred_boxes, pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def url_to_image(url, readFlag=cv2.IMREAD_COLOR):\n",
    "  resp = urlopen(url) \n",
    "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "  image = cv2.imdecode(image, readFlag)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_color_masks(image):\n",
    "  colors = [[0, 255, 0],[0, 0, 255],[255, 0, 0],[0, 255, 255],[255, 255, 0],[255, 0, 255],[80, 70, 180], [250, 80, 190],[245, 145, 50],[70, 150, 250],[50, 190, 190]]\n",
    "  r = np.zeros_like(image).astype(np.uint8)\n",
    "  g = np.zeros_like(image).astype(np.uint8)\n",
    "  b = np.zeros_like(image).astype(np.uint8)\n",
    "  r[image==1], g[image==1], b[image==1] = colors[random.randrange(0, 10)]\n",
    "  colored_mask = np.stack([r,g,b], axis=2)\n",
    "  return colored_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_segmentation(img_path, threshold=0.5, rect_th=3,\n",
    "                          text_size=3, text_th=3, url=False):\n",
    "  masks, boxes, pred_cls = get_prediction(img_path, threshold=threshold, url=url)\n",
    "  if url:\n",
    "    img = url_to_image(img_path) \n",
    "  else: \n",
    "    img = cv2.imread(img_path)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # For working with RGB images instead of BGR\n",
    "  for i in range(len(masks)):\n",
    "    if pred_cls[i] not in ['person', 'car']:\n",
    "      break\n",
    "    rgb_mask = random_color_masks(masks[i])\n",
    "    img = cv2.addWeighted(img, 1, rgb_mask, 0.5, 0)\n",
    "    pt1 = tuple(int(x) for x in boxes[i][0])\n",
    "    pt2 = tuple(int(x) for x in boxes[i][1])\n",
    "    cv2.rectangle(img, pt1, pt2, color=(0, 255, 0), thickness=rect_th)\n",
    "    # cv2.putText(img, pred_cls[i], pt1, cv2.FONT_HERSHEY_SIMPLEX, text_size, (0, 255, 0), thickness=text_th)\n",
    "  return img, pred_cls, masks[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_url = \"https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/10best-cars-group-cropped-1542126037.jpg\"\n",
    "# img_url = \"https://static.dw.com/image/52965592_605.jpg\"\n",
    "# img_url = \"https://pic.baike.soso.com/ugc/baikepic2/11855/cut-20211210180327-839430992_jpg_692_461_915662.jpg/1284\"\n",
    "img_url = \"https://uc.udn.com.tw/photo/2017/02/14/99/3175368.jpg\"\n",
    "\n",
    "img, pred_classes, masks = instance_segmentation(img_url, rect_th=2, text_th=1, url=True)\n",
    "\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f774c96c8c34c53ecd4c73b34542f198e825b7806220478caf5e39d6877a780"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
